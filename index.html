<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=0.8">
    <title>How Many Tokens Do 3D Point Cloud Transformer Architectures Really Need?</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="title">How Many Tokens Do 3D Point Cloud<br>Transformer Architectures Really Need?</h1>

            <div class="conference">NeurIPS 2025</div>

            <div class="authors">
                <a href="https://scholar.google.com/citations?user=5-0hLggAAAAJ&hl=en">Tuan Anh Tran</a><sup>1</sup> <a href="https://duyhominhnguyen.github.io/">Duy Minh Ho Nguyen</a><sup>2 1 3</sup> <a href="https://hchautran.github.io/">Hoai-Chau Tran</a><sup>4</sup> <a href="#">Michael Barz</a><sup>1</sup> <a href="#">Khoa D. Doan</a><sup>4</sup><br>
                <a href="#">Roger Wattenhofer</a><sup>5</sup> <a href="https://vienngo.github.io/">Vien Anh Ngo</a><sup>6</sup> <a href="https://www.matlog.net/">Mathias Niepert</a><sup>2 3</sup> <a href="https://www.dfki.de/~daso02/">Daniel Sonntag</a><sup>1 7</sup> <a href="https://www.sarmata.hhu.de/">Paul Swoboda</a><sup>8</sup>
            </div>
            
            <div class="affiliations">
                <sup>1</sup>German Research Centre for Artificial Intelligence (DFKI), <sup>2</sup>Max Planck Research School for Intelligent Systems (IMPRS-IS)
                <br>
                <sup>3</sup>University of Stuttgart <sup>4</sup>College of Engineering and Computer Science, VinUniversity <sup>5</sup>ETH Zurich <sup>6</sup>VinRobotics, Hanoi, Vietnam
                <br>
                <sup>7</sup>University of Oldenburg <sup>8</sup>Heinrich Heine University DÃ¼sseldorf
            </div>

            <div class="institution-logos">
                <div class="logos-row">
                    <img src="assets/dfki_logo.png" alt="DFKI" />
                    <img src="assets/university-of-stuttgart-logo.png" alt="University of Stuttgart" class="stuttgart-logo" />
                    <img src="assets/eth-zurich_logo.jpg" alt="ETH Zurich" class="eth-logo" />
                    <img src="assets/vinuniversity_logo.jpg" alt="VinUniversity" class="vinuni-logo" />
                </div>
                <div class="logos-row">
                    <img src="assets/mpi_imprs_is.png" alt="Max Planck Institute & IMPRS-IS" />
                    <img src="assets/hhu_logo.png" alt="Heinrich Heine University" class="hhu-logo" />
                    <img src="assets/logo_vinrobotics.png" alt="VinRobotics" />
                </div>
            </div>
            
            <!-- <div class="venues">
                Conference/Journal Name 2024
            </div> -->
            
            <div class="links">
                <a href="https://openreview.net/pdf?id=cFVQJepi4e" class="btn">ðŸ“„ Paper</a>
                <a href="#" class="btn">ðŸ“Š arXiv</a>
                <a href="https://github.com/anhtuanhsgs/GitMerge3D" class="btn">ðŸ’» Code</a>
                <a href="#video" class="btn">ðŸŽ¥ Video</a>
            </div>
        </div>

        <div class="content">
            <div class="section teaser">
                <div class="teaser-container">
                    <img src="assets/Teaser_Figure.png" alt="Performance and computational efficiency comparison" class="teaser-image" />
                    <div class="teaser-labels">
                        <p class="teaser-caption left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                                    Minimal Performance Loss</p>
                        <p class="teaser-caption right">Higher Computational Efficiency&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h2>Abstract</h2>
                <div class="abstract">
                    Recent advances in 3D point cloud transformers have led to state-of-the-art results in tasks such as semantic segmentation and reconstruction. However, these models typically rely on dense token representations, incurring high computational and memory costs during training and inference. In this work, we present the finding that tokens are remarkably redundant, leading to substantial inefficiency. We introduce an efficient token merging method and illustrate that it can reduce the token count by up to 90â€“95\% while maintaining competitive performance. This finding challenges the prevailing assumption that more tokens inherently yield better performance and highlights that many current models are over-tokenized and under-optimized for scalability. We validate our method across multiple 3D vision tasks and show consistent improvements in computational efficiency. This work is the first to assess redundancy in large-scale 3D transformer models, providing insights into the development of more efficient 3D foundation architectures.
                </div>
                
                <div class="contributions">
                    <h3>Key Contributions</h3>
                    <ul>
                        <li>A geometry-aware token merging strategy for 3D point cloud transformers</li>
                        <li>Dynamic token reduction algorithm based on globally informed graph</li>
                        <li>Significant computational efficiency gains while preserving geometric fidelity</li>
                    </ul>
                </div>
            </div>

            <div class="section">
                <h2>Method Overview</h2>
                <div class="method-content">
                    <div class="method-diagram">
                        <img src="assets/architecture.png" alt="GitMerge3D methodology diagram showing token merging pipeline" />
                        <p class="image-caption"><strong>a)</strong> For each Point Transformer layer, we compute global-informed energy scores, which are later used to calculate patch-level energy scores. <strong>b)</strong> These patch-level scores guide adaptive merging, retaining more information for high-energy patches. <strong>c)</strong> Each patch is divided into evenly sized bins, and destination tokens are randomly selected within these bins to enable spatially aware merging.</p>
                    </div>
                    
                    <div class="method-description">
                        <h3>Insights</h3>
                        <p>
                            3D point cloud tokens are highly redundant!
                        </p>

                        <div class="insights-visualization">
                            <div class="insights-carousel">
                                <button class="carousel-arrow left-arrow" onclick="changeScene(-1)">&#10094;</button>

                                <div class="carousel-content">
                                    <!-- Scene 1: scene0423_00 -->
                                    <div class="scene-slide active" data-scene="scene0423_00">
                                        <div class="insights-grid">
                                            <div class="insight-item">
                                                <img src="assets/scene0423_00_r0.05_frame0001/scene0423_00_r0.05_input.png" alt="Input point cloud" />
                                                <p class="insight-label">Input</p>
                                            </div>
                                            <div class="insight-item">
                                                <img src="assets/scene0423_00_r0.05_frame0001/scene0423_00_r0.05_21_attention.png" alt="Attention before merge" />
                                                <p class="insight-label">Feat. PCA (0% merge)</p>
                                            </div>
                                            <div class="insight-item">
                                                <img src="assets/scene0423_00_r0.90_frame0001/scene0423_00_r0.90_21_attention.png" alt="Attention after merge" />
                                                <p class="insight-label">Feat. PCA (90% merge)</p>
                                            </div>
                                            <div class="insight-item">
                                                <img src="assets/scene0423_00_r0.90_frame0001/scene0423_00_r0.90_21_energy_original.png" alt="Energy after merge" />
                                                <p class="insight-label">Energy (90% merge)</p>
                                            </div>
                                            <div class="insight-item">
                                                <img src="assets/scene0423_00_r0.90_frame0001/scene0423_00_r0.90_pred.png" alt="Prediction after merge" />
                                                <p class="insight-label">Prediction (90% merge)</p>
                                            </div>
                                            <div class="insight-item">
                                                <img src="assets/scene0423_00_r0.90_frame0001/scene0423_00_r0.90_difference.png" alt="Difference after merge" />
                                                <p class="insight-label">Difference (90% merge)</p>
                                            </div>
                                        </div>
                                    </div>

                                    <!-- Scene 2: scene0575_00 -->
                                    <div class="scene-slide" data-scene="scene0575_00">
                                        <div class="insights-grid">
                                            <div class="insight-item">
                                                <img src="assets/scene0575_00_r0.05_frame0001/scene0575_00_r0.05_input.png" alt="Input point cloud" />
                                                <p class="insight-label">Input</p>
                                            </div>
                                            <div class="insight-item">
                                                <img src="assets/scene0575_00_r0.05_frame0001/scene0575_00_r0.05_21_attention.png" alt="Attention before merge" />
                                                <p class="insight-label">Feat. PCA (0% merge)</p>
                                            </div>
                                            <div class="insight-item">
                                                <img src="assets/scene0575_00_r0.90_frame0001/scene0575_00_r0.90_21_attention.png" alt="Attention after merge" />
                                                <p class="insight-label">Feat. PCA (90% merge)</p>
                                            </div>
                                            <div class="insight-item">
                                                <img src="assets/scene0575_00_r0.90_frame0001/scene0575_00_r0.90_21_energy_original.png" alt="Energy after merge" />
                                                <p class="insight-label">Energy (90% merge)</p>
                                            </div>
                                            <div class="insight-item">
                                                <img src="assets/scene0575_00_r0.90_frame0001/scene0575_00_r0.90_pred.png" alt="Prediction after merge" />
                                                <p class="insight-label">Prediction (90% merge)</p>
                                            </div>
                                            <div class="insight-item">
                                                <img src="assets/scene0575_00_r0.90_frame0001/scene0575_00_r0.90_difference.png" alt="Difference after merge" />
                                                <p class="insight-label">Difference (90% merge)</p>
                                            </div>
                                        </div>
                                    </div>
                                </div>

                                <button class="carousel-arrow right-arrow" onclick="changeScene(1)">&#10095;</button>
                            </div>

                            <div class="scene-indicator">
                                <span class="dot active" onclick="goToScene(0)"></span>
                                <span class="dot" onclick="goToScene(1)"></span>
                            </div>

                            <div class="insights-caption">
                                <p class="image-caption"><strong>Observation</strong>: After merging 90% of the tokens in each attention layer, the attention visualization and predictions remain nearly identical to the original (5% merge baseline). The difference map (rightmost) shows minimal changes in <span style="color: red;">red</span>, demonstrating that there is high redundancy in the point cloud processing model.</p>
                            </div>
                        </div>

                        <div class="layer-videos-section">
                            <h3>Layer Visualization Videos</h3>
                            <div class="videos-grid">
                                <div class="video-item">
                                    <img src="assets/scene0356_00_feat_5_20_attn_0_original_video-ezgif.com-video-to-gif-converter.gif" alt="PCA Feature Layer 20 Animation" />
                                    <p class="video-label">PCA Feat. (Layer 20)</p>
                                </div>
                                <div class="video-item">
                                    <img src="assets/scene0356_00_feat_5_21_attn_0_original_video-ezgif.com-video-to-gif-converter.gif" alt="PCA Feature Layer 21 Animation" />
                                    <p class="video-label">PCA Feat. (Layer 21)</p>
                                </div>
                                <div class="video-item">
                                    <img src="assets/scene0356_00_feat_5_21_energy_original_video-ezgif.com-video-to-gif-converter.gif" alt="Energy Layer 21 Animation" />
                                    <p class="video-label">Energy (Layer 21)</p>
                                </div>
                            </div>
                        </div>

                        <div class="interactive-visualizer">
                            <h4>Interactive 3D Point Cloud Visualizer</h4>
                            <p class="visualizer-description">
                                Explore the token merging effects on a real 3D scene from ScanNet. This interactive visualizer shows the original point cloud and the results after applying our GitMerge3D method.
                            </p>
                            <div class="visualizer-container">
                                <iframe src="scene0645_02/index.html" width="100%" height="600px" frameborder="0"></iframe>
                            </div>
                            <p class="visualizer-caption">
                                <strong>Interactive Demo</strong>: Use mouse controls to navigate the 3D scene. Compare different layers and attention heads to see how our token merging preserves important geometric features while reducing computational complexity.
                            </p>
                        </div>
                    </div>
                </div>
            </div>

            <div class="section results">
                <div class="results-content">
                    <h2>Results</h2>
                    
                    <div class="results-grid">
                        <div class="result-item">
                            <img src="assets/computational-efficiency.png" alt="Computational efficiency comparison" />
                            <h3>Computational Efficiency</h3>
                            <p>GitMerge3D achieves up to 21% in computational cost while maintaining with minimal change in accuracy on point cloud tasks.</p>
                        </div>
                        
                        <div class="result-item">
                            <img src="assets/memory-saving.png" alt="Memory usage reduction" />
                            <h3>Memory Optimization</h3>
                            <p>Our token merging strategy reduces peak memory usage significantly during inference, enabling processing of larger point clouds on resource-constrained devices.</p>
                        </div>
                        
                        <div class="result-item">
                            <img src="assets/feature-preservation.png" alt="Geometric feature preservation visualization" />
                            <h3>Feature Preservation</h3>
                            <p>GitMerge3D maintains critical geometric features even with aggressive token reduction.</p>
                        </div>
                    </div>
                    
                    <div class="segmentation-results">
                        <img src="assets/segmentation-results.png" alt="ScanNet segmentation results comparison" class="full-width-image" />
                        <p class="image-caption">Illustration of ScanNet segmentation results with and without our merging method. As shown in the fourth column, the differences - highlighted in red - are limited to only a few points among hundreds of thousands.</p>
                    </div>
                    
                    <div class="segmentation-results">
                        <img src="assets/reconstruction-results.png" alt="3D object reconstruction comparison" class="full-width-image" />
                        <p class="image-caption">We visualize the output of various token compression techniques after removing 80% of the tokens, comparing their visual quality degradation (or preservation) on the 3D object reconstruction task</p>
                    </div>
                </div>
            </div>

            <div class="section video-section" id="video">
                <h2>Video Presentation</h2>
                <div class="video-container">
                    <iframe src="https://www.youtube.com/embed/N_CRjhiIjrA"
                            frameborder="0"
                            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                            allowfullscreen>
                    </iframe>
                </div>
            </div>

            <div class="section acknowledgement">
                <h2>Acknowledgement</h2>
                <div class="acknowledgement-content">
                    <p>This work was supported by Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's Excellence Strategy - EXC 2075 â€“ 390740016, the DARPA ANSR program under award FA8750-23-2-0004, the DARPA CODORD program under award HR00112590089. The authors thank the International Max Planck Research School for Intelligent Systems (IMPRS-IS) for supporting Duy M. H. Nguyen. Tuan Anh Tran, Duy M. H. Nguyen, Michael Barz and Daniel Sonntag are also supported by the No-IDLE project (BMBF, 01IW23002), the MASTER project (EU, 101093079), and the Endowed Chair of Applied Artificial Intelligence, Oldenburg University.</p>
                </div>
            </div>

            <div class="section citation">
                <h2>Citation</h2>
                <div class="bibtex">
                    <pre>@inproceedings{gitmerge3d2025,
    title={How Many Tokens Do 3D Point Cloud Transformer Architectures Really Need?},
    author={Tuan Anh Tran and Duy Minh Ho Nguyen and Hoai-Chau Tran and Michael Barz and Khoa D. Doan and Roger Wattenhofer and Vien Anh Ngo and Mathias Niepert and Daniel Sonntag and Paul Swoboda},
    booktitle={Advances in Neural Information Processing Systems},
    year={2025}
}</pre>
                </div>
                <button class="copy-btn" onclick="copyBibtex()">Copy Citation</button>
            </div>
        </div>
    </div>

    <script>
        function copyBibtex() {
            const bibtexText = document.querySelector('.bibtex pre').textContent;
            navigator.clipboard.writeText(bibtexText).then(() => {
                const btn = document.querySelector('.copy-btn');
                const originalText = btn.textContent;
                btn.textContent = 'Copied!';
                setTimeout(() => {
                    btn.textContent = originalText;
                }, 2000);
            });
        }

        // Carousel functionality for scene switching
        let currentScene = 0;
        const slides = document.querySelectorAll('.scene-slide');
        const dots = document.querySelectorAll('.dot');

        function showScene(n) {
            if (n >= slides.length) { currentScene = 0; }
            if (n < 0) { currentScene = slides.length - 1; }

            // Hide all slides
            slides.forEach(slide => {
                slide.classList.remove('active');
            });

            // Remove active class from all dots
            dots.forEach(dot => {
                dot.classList.remove('active');
            });

            // Show current slide and activate corresponding dot
            slides[currentScene].classList.add('active');
            dots[currentScene].classList.add('active');
        }

        function changeScene(direction) {
            currentScene += direction;
            showScene(currentScene);
        }

        function goToScene(n) {
            currentScene = n;
            showScene(currentScene);
        }
    </script>
</body>
</html>